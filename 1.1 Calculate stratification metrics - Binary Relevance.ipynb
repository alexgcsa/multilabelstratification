{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pylocker import Locker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_from_arff, load_dataset_dump\n",
    "import cPickle as pickle\n",
    "import copy\n",
    "from itertools import chain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sets = {\n",
    "    'bibtex': 159,\n",
    "    'Corel5k': 374,\n",
    "    'delicious': 983,\n",
    "    'genbase': 27,\n",
    "    'emotions': 6,\n",
    "    'enron': 53,\n",
    "    'mediamill': 101,\n",
    "    'medical': 45,\n",
    "    'scene': 6,\n",
    "    'tmc2007-500': 22,\n",
    "    'yeast': 14,\n",
    "    'rcv1subset1': 101,\n",
    "    'rcv1subset2': 101,\n",
    "    'rcv1subset3': 101,\n",
    "    'rcv1subset4': 101,\n",
    "    'rcv1subset5': 101,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize the experiment\n",
    "is_done = {s : [v , False] for s,v  in sets.iteritems()}\n",
    "with open(\"./prediction_br_probs.json\", \"w\") as fp:\n",
    "    fp.write(jsonpickle.dumps(is_done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_me_set():\n",
    "    #  create a unique lock pass. This can be any string.\n",
    "    lpass = str(uuid.uuid1())\n",
    "\n",
    "    # create locker instance\n",
    "    FL = Locker(filePath=\"./prediction_br.json\", lockPass=lpass,mode='r+')\n",
    "\n",
    "    # acquire the lock\n",
    "    with FL as r:\n",
    "        acquired, code, fd  = r\n",
    "\n",
    "        # check if aquired.\n",
    "        if fd is not None:\n",
    "            a = jsonpickle.loads(fd.read())\n",
    "            s = filter(lambda z: a[z][1] is not True, sorted(a.keys(), key=lambda x: a[x][0]))\n",
    "            if len(s) == 0:\n",
    "                return None\n",
    "            \n",
    "            s=s[0]\n",
    "            a[s][1]=True\n",
    "            fd.seek(0)\n",
    "            fd.write(jsonpickle.dumps(a))\n",
    "            fd.truncate()\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.cluster import IGraphLabelCooccurenceClusterer\n",
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from scipy.sparse import hstack, coo_matrix, csc_matrix\n",
    "from sklearn.utils import check_array\n",
    "import copy\n",
    "\n",
    "\n",
    "class BinaryRelevance(ProblemTransformationBase):\n",
    "\n",
    "    \"\"\"Binary Relevance Multi-Label Classifier.\n",
    "\n",
    "    Transforms a multi-label classification problem with L labels\n",
    "    into L single-label separate binary classification problems\n",
    "    using the same base classifier provided in the constructor. The\n",
    "    prediction output is the union of all per label classifiers.\n",
    "\n",
    "    :param classifier: clonable scikit-compatible base classifier\n",
    "    :type classifier: :py:class:`sklearn.base.BaseEstimator` or compatible\n",
    "\n",
    "    :param require_dense: whether the base classifier requires dense\n",
    "        representations for input features and classes/labels matrices in fit/predict.\n",
    "    :type require_dense: [bool, bool]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    BRIEFNAME = \"BR\"\n",
    "\n",
    "    def __init__(self, classifier=None, require_dense=None):\n",
    "        super(BinaryRelevance, self).__init__(classifier, require_dense)\n",
    "\n",
    "    def generate_partition(self, X, y):\n",
    "        \"\"\" Partitions the label space into singletons\n",
    "\n",
    "            :param X: not used\n",
    "            :param y: binary indicator matrix with label assignments -\n",
    "                only used for learning # of labels\n",
    "            :type y: matrix or sparse matrix\n",
    "\n",
    "            Sets self.partition (list of single item lists) and self.model_count (equal to number of labels)\n",
    "\n",
    "        \"\"\"\n",
    "        self.partition = list(range(y.shape[1]))\n",
    "        self.model_count = y.shape[1]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit classifier with training data\n",
    "\n",
    "        Internally this method uses a sparse CSR representation for X\n",
    "        (:py:class:`scipy.sparse.csr_matrix`) and sparse CSC representation for y\n",
    "        (:py:class:`scipy.sparse.csc_matrix`).\n",
    "\n",
    "        :param X: input features\n",
    "        :type X: dense or sparse matrix (n_samples, n_features)\n",
    "        :param y: binary indicator matrix with label assignments\n",
    "        :type y: dense or sparse matrix of {0, 1} (n_samples, n_labels)\n",
    "        :returns: Fitted instance of self\n",
    "\n",
    "        \"\"\"\n",
    "        X = self.ensure_input_format(\n",
    "            X, sparse_format='csr', enforce_sparse=True)\n",
    "        y = self.ensure_output_format(\n",
    "            y, sparse_format='csc', enforce_sparse=True)\n",
    "\n",
    "        self.generate_partition(X, y)\n",
    "        self.classifiers = []\n",
    "\n",
    "        for i in range(self.model_count):\n",
    "            classifier = copy.deepcopy(self.classifier)\n",
    "            y_subset = self.generate_data_subset(y, self.partition[i], axis=1)\n",
    "            classifier.fit(self.ensure_input_format(\n",
    "                X), self.ensure_output_format(y_subset))\n",
    "            self.classifiers.append(classifier)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels for X\n",
    "\n",
    "        Internally this method uses a sparse CSR representation for X\n",
    "        (:py:class:`scipy.sparse.coo_matrix`).\n",
    "\n",
    "        :param X: input features\n",
    "        :type X: dense or sparse matrix (n_samples, n_features)\n",
    "        :returns: binary indicator matrix with label assignments\n",
    "        :rtype: sparse matrix of int (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        predictions = [self.ensure_multi_label_from_single_class(\n",
    "            self.classifiers[label].predict(self.ensure_input_format(X)))\n",
    "            for label in range(self.model_count)]\n",
    "\n",
    "        return hstack(predictions)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities of label assignments for X\n",
    "\n",
    "        Internally this method uses a sparse CSR representation for X\n",
    "        (:py:class:`scipy.sparse.coo_matrix`).\n",
    "\n",
    "        :param X: input features\n",
    "        :type X: dense or sparse matrix (n_samples, n_labels)\n",
    "        :returns: matrix with label assignment probabilities\n",
    "        :rtype: sparse matrix of float (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = []\n",
    "        for label in range(self.model_count):\n",
    "            binary_prediction = self.classifiers[label].predict_proba(self.ensure_input_format(X))\n",
    "            if binary_prediction.shape[1] == 2:\n",
    "                binary_prediction=self.ensure_multi_label_from_single_class(binary_prediction[:, 1])\n",
    "            elif binary_prediction.shape[1] == 1:\n",
    "                if self.classifiers[label].classes_[0]==1:\n",
    "                    binary_prediction = np.matrix(np.ones(X.shape[0])).T\n",
    "                else:\n",
    "                    binary_prediction = csc_matrix((X.shape[0],1))\n",
    "            else:\n",
    "                raise Exception(\"Invalid shape of binary prediction\")\n",
    "\n",
    "            predictions.append(binary_prediction)\n",
    "\n",
    "        return hstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_set(s):\n",
    "    data = load_dataset_dump('./dumps/{}.scikitml.bz2'.format(s))    \n",
    "\n",
    "    with open(\"./folds/{}.pickle\".format(s),\"r\") as fp:\n",
    "        fold_data = pickle.load(fp)\n",
    "\n",
    "    return data, fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def classify(s):\n",
    "    n_splits = 10\n",
    "    print s, n_splits, time.time()\n",
    "    data, fold_data = load_set(s)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    label_count = y.shape[1]\n",
    "    predictions = {n : [None for i in range(n_splits)] for n in fold_data}\n",
    "    probs = {n : [None for i in range(n_splits)] for n in fold_data}\n",
    "    times = {name: [] for name in fold_data}\n",
    "    left = len(fold_data) * n_splits\n",
    "    for name, f in fold_data.iteritems():\n",
    "        for split in range(n_splits):\n",
    "            mean = np.mean([np.mean(x) if len(x) > 0 else 0.0 for x in times.values()])\n",
    "\n",
    "            t = time.time()\n",
    "            print s, name, split, str(datetime.datetime.fromtimestamp(t+mean)), str(datetime.datetime.fromtimestamp(t+left*mean))\n",
    "            left -= 1\n",
    "            \n",
    "            if len(f[split])==2:\n",
    "                train_idx = f[split][0]\n",
    "                test_idx = f[split][1]\n",
    "            else:\n",
    "                train_idx = list(chain.from_iterable([f[i] for i in xrange(n_splits) if i!=split]))\n",
    "                test_idx=f[split]\n",
    "                \n",
    "            # assifier = LabelSpacePartitioningClassifier(problem_transform_classifier, clusterer)\n",
    "            # construct base forest classifier\n",
    "            base_classifier = RandomForestClassifier()\n",
    "\n",
    "            # setup problem transformation approach with sparse matrices for random forest\n",
    "            classifier = BinaryRelevance(classifier=base_classifier,\n",
    "                require_dense=[False, True])\n",
    "            classifier.fit(X[train_idx,:], y[train_idx,:])\n",
    "\n",
    "            predictions[name][split]= classifier.predict(X[test_idx,:])\n",
    "            probs[name][split]= classifier.predict_proba(X[test_idx,:])\n",
    "            t_end = time.time() - t\n",
    "            times[name].append(t_end)\n",
    "\n",
    "    with open (\"./predictions/br/{}.pickle\".format(s), \"w\") as fp:\n",
    "        pickle.dump([predictions, probs, times], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s = get_me_set()\n",
    "while s is not None:\n",
    "    classify(s)\n",
    "    s = get_me_set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
