{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!mkdir folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_from_arff, load_dataset_dump\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import pandas as pd\n",
    "import copy\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from builtins import str\n",
    "from builtins import range\n",
    "from builtins import object\n",
    "import arff\n",
    "import bz2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import shutil\n",
    "from os import environ\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "from os.path import exists\n",
    "from os.path import expanduser\n",
    "from os.path import isdir\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "from os import makedirs\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tsoumakas_fold(n_splits, y):\n",
    "    y_train = lil_matrix(y)\n",
    "    n_samples = y_train.shape[0]\n",
    "    n_labels = y_train.shape[1]\n",
    "    percentage_per_fold = [1/float(n_splits) for i in range(n_splits)]\n",
    "    desired_samples_per_fold = np.array([percentage_per_fold[i]*n_samples for i in range(n_splits)])\n",
    "\n",
    "    folds = [[] for i in range(n_splits)]\n",
    "\n",
    "    samples_with_label = [[] for i in range(n_labels)]\n",
    "\n",
    "    for sample, labels in enumerate(y_train.rows):\n",
    "        for label in labels:\n",
    "            samples_with_label[label].append(sample)\n",
    "\n",
    "    desired_samples_per_label_per_fold = {i: [len(samples_with_label[i])*percentage_per_fold[j] for j in range(n_splits)] for i in range(n_labels)}\n",
    "\n",
    "    rows_used = {i : False for i in range(n_samples)}\n",
    "    labeled_samples_available = map(len, samples_with_label)\n",
    "    total_labeled_samples_available = sum(labeled_samples_available)\n",
    "    while total_labeled_samples_available > 0:\n",
    "        l = np.argmin(np.ma.masked_equal(labeled_samples_available, 0, copy=False))\n",
    "\n",
    "        while len(samples_with_label[l])>0:\n",
    "            row = samples_with_label[l].pop()\n",
    "            if rows_used[row]:\n",
    "                continue\n",
    "\n",
    "            max_val = max(desired_samples_per_label_per_fold[l])\n",
    "            M = np.where(np.array(desired_samples_per_label_per_fold[l])==max_val)[0]\n",
    "            m = None\n",
    "            if len(M) == 1:\n",
    "                m = M[0]\n",
    "            else:\n",
    "                max_val = max(desired_samples_per_fold[M])\n",
    "                M_prim = np.where(np.array(desired_samples_per_fold)==max_val)[0]\n",
    "                M_prim = np.array([x for x in M_prim if x in M])\n",
    "                m = np.random.choice(M_prim, 1)[0]\n",
    "\n",
    "            folds[m].append(row)\n",
    "            rows_used[row]=True\n",
    "            for i in y_train.rows[row]:\n",
    "                desired_samples_per_label_per_fold[i][m]-=1\n",
    "            desired_samples_per_fold[m]-=1\n",
    "\n",
    "        labeled_samples_available = map(len, samples_with_label)\n",
    "        total_labeled_samples_available = sum(labeled_samples_available)\n",
    "\n",
    "    available_samples = [i for i, v in rows_used.iteritems() if not v]\n",
    "    samples_left = len(available_samples)\n",
    "\n",
    "    assert (samples_left + sum(map(len, folds))) == n_samples\n",
    "\n",
    "    while samples_left>0:\n",
    "        row = available_samples.pop()\n",
    "        rows_used[row]=True\n",
    "        fold_selected = np.random.choice(np.where(desired_samples_per_fold>0)[0], 1)[0]\n",
    "        folds[fold_selected].append(row)\n",
    "        samples_left-=1\n",
    "\n",
    "    assert sum(map(len, folds)) == n_samples\n",
    "    assert len([i for i, v in rows_used.iteritems() if not v])==0\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def szymanski_ts_eq_fold(n_splits, y):\n",
    "\n",
    "    y_train = lil_matrix(y)\n",
    "\n",
    "    n_samples = y_train.shape[0]\n",
    "    n_labels = y_train.shape[1]\n",
    "\n",
    "    percentage_per_fold = [1/float(n_splits) for i in range(n_splits)]\n",
    "    desired_samples_per_fold = np.array([percentage_per_fold[i]*n_samples for i in range(n_splits)])\n",
    "\n",
    "    folds = [[] for i in range(n_splits)]\n",
    "\n",
    "    samples_with_label = [[] for i in range(n_labels)]\n",
    "\n",
    "    for sample, labels in enumerate(y_train.rows):\n",
    "        for label in labels:\n",
    "            samples_with_label[label].append(sample)\n",
    "\n",
    "    samples_with_labelpairs = {}\n",
    "    for row, labels in enumerate(y_train.rows):\n",
    "        pairs = [(a, b) for b in labels for a in labels if a <= b]\n",
    "        for p in pairs:\n",
    "            if p not in samples_with_labelpairs:\n",
    "                samples_with_labelpairs[p] = []\n",
    "            samples_with_labelpairs[p].append(row)\n",
    "\n",
    "    desired_samples_per_labelpair_per_fold = {k : [len(v)*i for i in percentage_per_fold] for k,v in samples_with_labelpairs.iteritems()}\n",
    "\n",
    "    labels_of_edges = samples_with_labelpairs.keys()\n",
    "    labeled_samples_available = [len(samples_with_labelpairs[v]) for v in labels_of_edges]\n",
    "\n",
    "    rows_used = {i : False for i in range(n_samples)}\n",
    "    total_labeled_samples_available = sum(labeled_samples_available)\n",
    "    old_l=None\n",
    "\n",
    "    while total_labeled_samples_available > 0:\n",
    "        l = labels_of_edges[np.argmin(np.ma.masked_equal(labeled_samples_available, 0, copy=False))]\n",
    "\n",
    "\n",
    "        while len(samples_with_labelpairs[l])>0:\n",
    "\n",
    "            row = samples_with_labelpairs[l].pop()\n",
    "            if rows_used[row]:\n",
    "                continue\n",
    "\n",
    "            max_val = max(desired_samples_per_labelpair_per_fold[l])\n",
    "            M = np.where(np.array(desired_samples_per_labelpair_per_fold[l])==max_val)[0]\n",
    "        #    print l, M, len(M)\n",
    "\n",
    "            m = None\n",
    "            if len(M) == 1:\n",
    "                m = M[0]\n",
    "            else:\n",
    "                max_val = max(desired_samples_per_fold[M])\n",
    "                M_bis = np.where(np.array(desired_samples_per_fold)==max_val)[0]\n",
    "                M_bis = np.array([x for x in M_bis if x in M])\n",
    "                m = np.random.choice(M_bis, 1)[0]\n",
    "        #        print M_prim,m, max_val, desired_samples_per_labelpair_per_fold[l]\n",
    "\n",
    "            folds[m].append(row)\n",
    "            rows_used[row]=True\n",
    "            desired_samples_per_labelpair_per_fold[l][m]-=1\n",
    "            if desired_samples_per_labelpair_per_fold[l][m] <0:\n",
    "                desired_samples_per_labelpair_per_fold[l][m]=0\n",
    "\n",
    "            for i in samples_with_labelpairs.iterkeys():\n",
    "                if row in samples_with_labelpairs[i]:\n",
    "                    samples_with_labelpairs[i].remove(row)\n",
    "                    desired_samples_per_labelpair_per_fold[i][m]-=1\n",
    "\n",
    "                if desired_samples_per_labelpair_per_fold[i][m] <0:\n",
    "                    desired_samples_per_labelpair_per_fold[i][m]=0\n",
    "            desired_samples_per_fold[m]-=1\n",
    "\n",
    "        labeled_samples_available = [len(samples_with_labelpairs[v]) for v in labels_of_edges]\n",
    "        total_labeled_samples_available = sum(labeled_samples_available)\n",
    "\n",
    "        available_samples = [i for i, v in rows_used.iteritems() if not v]\n",
    "        samples_left = len(available_samples)\n",
    "\n",
    "    labeled_samples_available = map(len, samples_with_label)\n",
    "    total_labeled_samples_available = sum(labeled_samples_available)\n",
    "\n",
    "    while total_labeled_samples_available > 0:\n",
    "        l = np.argmin(np.ma.masked_equal(labeled_samples_available, 0, copy=False))\n",
    "\n",
    "        while len(samples_with_label[l])>0:\n",
    "            row = samples_with_label[l].pop()\n",
    "            if rows_used[row]:\n",
    "                continue\n",
    "\n",
    "            max_val = max(desired_samples_per_label_per_fold[l])\n",
    "            M = np.where(np.array(desired_samples_per_label_per_fold[l])==max_val)[0]\n",
    "            m = None\n",
    "            if len(M) == 1:\n",
    "                m = M[0]\n",
    "            else:\n",
    "                max_val = max(desired_samples_per_fold[M])\n",
    "                M_prim = np.where(np.array(desired_samples_per_fold)==max_val)[0]\n",
    "                M_prim = np.array([x for x in M_prim if x in M])\n",
    "                m = np.random.choice(M_prim, 1)[0]\n",
    "\n",
    "            folds[m].append(row)\n",
    "            rows_used[row]=True\n",
    "            for i in y_train.rows[row]:\n",
    "                desired_samples_per_label_per_fold[i][m]-=1\n",
    "            desired_samples_per_fold[m]-=1\n",
    "\n",
    "        labeled_samples_available = map(len, samples_with_label)\n",
    "        total_labeled_samples_available = sum(labeled_samples_available)\n",
    "\n",
    "    assert (samples_left + sum(map(len, folds))) == n_samples\n",
    "\n",
    "    while samples_left>0:\n",
    "        row = available_samples.pop()\n",
    "        rows_used[row]=True\n",
    "        fold_selected = np.random.choice(np.where(desired_samples_per_fold>0)[0], 1)[0]\n",
    "        folds[fold_selected].append(row)\n",
    "        samples_left-=1\n",
    "\n",
    "    assert sum(map(len, folds)) == n_samples\n",
    "    assert len([i for i, v in rows_used.iteritems() if not v])==0\n",
    "    return folds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def standard_kfolds(n_splits, y):\n",
    "    kf = KFold(n_splits, shuffle=False)\n",
    "    folds3 = [x[1] for x in list(kf.split(np.zeros(y.shape[0]),y))]\n",
    "    return folds3\n",
    "\n",
    "class Transfomer:\n",
    "    def transform_to_multiclass(self, y):\n",
    "        self.label_count = y.shape[1]\n",
    "        self.unique_combinations = {}\n",
    "        self.reverse_combinations=[]\n",
    "        self.last_id = 0\n",
    "        train_vector = []\n",
    "        for labels_applied in y.rows:\n",
    "            label_string = \",\".join(map(str, labels_applied))\n",
    "\n",
    "            if label_string not in self.unique_combinations:\n",
    "                self.unique_combinations[label_string] = self.last_id\n",
    "                self.reverse_combinations.append(labels_applied)\n",
    "                self.last_id += 1\n",
    "\n",
    "            train_vector.append(self.unique_combinations[label_string])\n",
    "        return train_vector\n",
    "    \n",
    "def stratified_folds(n_splits, y):\n",
    "    t=Transfomer()\n",
    "    kf = StratifiedKFold(n_splits=n_splits, random_state=None, shuffle=False)\n",
    "    folds4 = [x[1] for x in list(kf.split(np.zeros(y.shape[0]),t.transform_to_multiclass(y)))]\n",
    "    return folds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sets = {\n",
    "    'bibtex': 159,\n",
    "    'Corel5k': 374,\n",
    "    'delicious': 983,\n",
    "    'genbase': 27,\n",
    "    'emotions': 6,\n",
    "    'enron': 53,\n",
    "    'mediamill': 101,\n",
    "    'medical': 45,\n",
    "    'scene': 6,\n",
    "    'tmc2007-500': 22,\n",
    "    'yeast': 14,\n",
    "    'rcv1subset1': 101,\n",
    "    'rcv1subset2': 101,\n",
    "    'rcv1subset3': 101,\n",
    "    'rcv1subset4': 101,\n",
    "    'rcv1subset5': 101,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_dataset_dump(filename, input_space, labels, feature_names, label_names):\n",
    "        \"\"\"Saves a compressed data set dump\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        filename : string\n",
    "            Path to dump file, if without .bz2, the .bz2 extension will be appended.\n",
    "\n",
    "        input_space: array-like of array-likes\n",
    "            Input space array-like of input feature vectors\n",
    "\n",
    "        labels: array-like of binary label vectors\n",
    "            Array-like of labels assigned to each input vector, as a binary indicator vector (i.e. if 5th position has value 1\n",
    "            then the input vector has label no. 5)\n",
    "        \"\"\"\n",
    "        if filename[-4:] != '.bz2':\n",
    "            filename += \".bz2\"\n",
    "\n",
    "        with bz2.BZ2File(filename, \"wb\") as file_handle:\n",
    "            pickle.dump({'X': input_space, 'y': labels, 'features': feature_names, 'labels': label_names}, file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "for s in sorted(sets.keys(), key=lambda x: sets[x]):\n",
    "    print s, str(datetime.datetime.now())\n",
    "    data = load_dataset_dump('./dumps/{}.scikitml.bz2'.format(s))\n",
    "    y = data['y']\n",
    "\n",
    "    folds = {\n",
    "        'IS': tsoumakas_fold(n_splits, y),\n",
    "        'kfold': standard_kfolds(n_splits, y),\n",
    "        'SOIS': szymanski_ts_eq_fold(n_splits, y),\n",
    "        'stratified': stratified_folds(n_splits, y)        \n",
    "    }\n",
    "    \n",
    "    with open(\"./folds/{}.pickle\".format(s),\"w\") as fp:\n",
    "        pickle.dump(folds, fp)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
