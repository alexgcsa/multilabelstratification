{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import jsonpickle.ext.numpy as jsonpickle_numpy\n",
    "jsonpickle_numpy.register_handlers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_from_arff, load_dataset_dump\n",
    "import cPickle as pickle\n",
    "import copy\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sets = {\n",
    "    'bibtex': 159,\n",
    "    'Corel5k': 374,\n",
    "    'delicious': 983,\n",
    "    'genbase': 27,\n",
    "    'emotions': 6,\n",
    "    'enron': 53,\n",
    "    'mediamill': 101,\n",
    "    'medical': 45,\n",
    "    'scene': 6,\n",
    "    'tmc2007-500': 22,\n",
    "    'yeast': 14,\n",
    "    'rcv1subset1': 101,\n",
    "    'rcv1subset2': 101,\n",
    "    'rcv1subset3': 101,\n",
    "    'rcv1subset4': 101,\n",
    "    'rcv1subset5': 101,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifiermetrics = {\n",
    "    'precision-macro': lambda x,y: metrics.precision_score(x,y,average='macro'),\n",
    "    'hamming_loss': metrics.hamming_loss,\n",
    "    'accuracy_score': metrics.accuracy_score,    \n",
    "}\n",
    "\n",
    "probsmetrics = {\n",
    "    'coverage_error': metrics.coverage_error,\n",
    "    'label_ranking_loss': metrics.label_ranking_loss,\n",
    "    'roc_auc-micro': lambda x, y: metrics.roc_auc_score(x,y, average='micro'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_set(s):\n",
    "    data = load_dataset_dump('./dumps/{}.scikitml.bz2'.format(s))    \n",
    "\n",
    "    with open(\"./folds/{}.pickle\".format(s),\"r\") as fp:\n",
    "        fold_data = pickle.load(fp)\n",
    "\n",
    "    return data, fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def measure(s, measures, probsmeasures, source):\n",
    "    n_splits = 10\n",
    "    print s, n_splits, time.time()\n",
    "    data, fold_data = load_set(s)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    with open (\"./predictions/{}/{}.pickle\".format(source,s), \"r\") as fp:\n",
    "        d = pickle.load(fp)\n",
    "        \n",
    "    predictions = d[0]\n",
    "    probs = d[1]\n",
    "    \n",
    "    label_count = y.shape[1]\n",
    "    \n",
    "    results = {m: {n:[] for n in fold_data} for m in measures.keys()+probsmeasures.keys()}\n",
    "    \n",
    "    for name, f in fold_data.iteritems():\n",
    "        for split in range(n_splits):\n",
    "            if len(f[split])==2:\n",
    "                train_idx = f[split][0]\n",
    "                test_idx = f[split][1]\n",
    "            else:\n",
    "                train_idx = list(chain.from_iterable([f[i] for i in xrange(n_splits) if i!=split]))\n",
    "                test_idx=f[split]\n",
    "                \n",
    "            for m,fun in measures.iteritems():\n",
    "                results[m][name].append(fun(y[test_idx,:].todense(), predictions[name][split].todense()))\n",
    "                \n",
    "            for m,fun in probsmeasures.iteritems():\n",
    "                results[m][name].append(fun(y[test_idx,:].todense(), probs[name][split].todense()))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = {src : {s: measure(s, classifiermetrics, probsmetrics, src) for s in sets} for src in ['br', 'lp']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from skmultilearn.cluster import IGraphLabelCooccurenceClusterer\n",
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def measure_graph(s, measures, probsmeasures):\n",
    "    n_splits = 10\n",
    "    print s, n_splits, time.time()\n",
    "    data, fold_data = load_set(s)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    with open (\"./predictions/graphs/{}.pickle\".format(s), \"r\") as fp:\n",
    "        d = pickle.load(fp)\n",
    "        \n",
    "    results = {}\n",
    "    modularities = {}\n",
    "    communities = {}\n",
    "    test_mods = {}\n",
    "    test_parts = {}\n",
    "    \n",
    "    for graph_method in [('fastgreedy', True), ('fastgreedy', False)]:\n",
    "        predictions = d[0][graph_method]\n",
    "        probs = d[1][graph_method]\n",
    "        m_name = \"FG\"\n",
    "        if graph_method[1]:\n",
    "            m_name+='W'\n",
    "\n",
    "        label_count = y.shape[1]\n",
    "\n",
    "        results[m_name] = {m: {n:[] for n in fold_data} for m in measures.keys()+probsmeasures.keys()}\n",
    "        \n",
    "        communities[m_name]={k:map(list,v) for k,v in d[3][graph_method].iteritems()}\n",
    "        modularities[m_name]=copy.copy(d[4][graph_method])\n",
    "        test_parts[m_name] =  {n:[] for n in fold_data}\n",
    "        test_mods[m_name] =  {n:[] for n in fold_data}\n",
    "        \n",
    "        for name, f in fold_data.iteritems():\n",
    "            for split in range(n_splits):\n",
    "                if len(f[split])==2:\n",
    "                    train_idx = f[split][0]\n",
    "                    test_idx = f[split][1]\n",
    "                else:\n",
    "                    train_idx = list(chain.from_iterable([f[i] for i in xrange(n_splits) if i!=split]))\n",
    "                    test_idx=f[split]\n",
    "\n",
    "                for m,fun in measures.iteritems():\n",
    "                    results[m_name][m][name].append(fun(y[test_idx,:].todense(), predictions[name][split].todense()))\n",
    "\n",
    "                for m,fun in probsmeasures.iteritems():\n",
    "                    results[m_name][m][name].append(fun(y[test_idx,:].todense(), probs[name][split].todense()))\n",
    "                    \n",
    "                clusterer = IGraphLabelCooccurenceClusterer(graph_method[0], weighted=graph_method[1], include_self_edges=False)\n",
    "                clusterer.fit_predict(None, y[test_idx,:])\n",
    "                test_mods[m_name][name].append(clusterer.partition.modularity)\n",
    "                test_parts[m_name][name].append(copy.copy(list(clusterer.partition)))\n",
    "                \n",
    "    return results, communities, modularities, test_mods, test_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r_graph = {s: measure_graph(s, classifiermetrics, probsmetrics) for s in sets if s != 'delicious'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "set(r_graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "available_network_methods = r_graph['scene'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r_graph['scene'][0]['FG'].keys() == data['br']['scene'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for m in available_network_methods:\n",
    "    print m\n",
    "    data[m] = {s: r_graph[s][0][m] for s in r_graph}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"./results/classification.json\",\"wb\") as fp:\n",
    "    fp.write(jsonpickle.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph_data = [\"train_communities\", \"train_modularities\", \"test_modularities\", \"test_communities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph_data_dict = {s : {v : r_graph[s][k+1] for k, v in enumerate(graph_data)} for s in r_graph}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"./results/networks.json\",\"wb\") as fp:\n",
    "    fp.write(jsonpickle.dumps(graph_data_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
